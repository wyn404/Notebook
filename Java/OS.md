## [进程和线程的区别](#jump1)
## [进程有哪几种状态](#jump2)
## [进程间的通信常见的有哪几种方式](#jump3)
## [线程间的同步方式](#jump4)
## [系统中进程的调度算法](#jump5)
## [什么是死锁，产生死锁的四个必要条件是什么](#jump6)
## [内存管理有哪几种方式](#jump7)
## [快表和多级页表](#jump8)
## [分页机制和分段机制的共同点和区别](#jump9)
## [CPU寻址方式及虚拟地址空间](#jump10)
## [虚拟内存和局部性原理](#jump11)
## [虚拟内存技术的实现](#jump12)
## [页面置换算法](#jump13)

## 进程和线程的区别
<span id="jump1">
相同点：

进程和线程都有ID/寄存器组、状态和优先权、信息块，创建后都可以有自己的属性，都可与父进程共享资源、都不直接访问其他无关进程或线程的资源。

线程是独立调度的基本单位，进程是资源分配的基本单位。
线程是进程划分成更小的运行单位，一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；进程则相反。多个线程共享进程的堆和方法区资源，但是每个线程有自己的程序计数器、虚拟机栈和本地方法栈。

线程的出现是为了解决上下文切换复杂的缺点。进程的并发必然需要在进程间切换，每个进程都有自己独立的地址空间，在切换时需要换入到新的地址空间中执行，效率较低。线程实现了在进程内部并发，解决了一个进程只能干一个事。多个线程之间公用一个进程的地址空间，在切换的时候效率更高。
</span>

## 进程有哪几种状态
<span id="jump2">

* __创建状态__：进程正在被创建，尚未到就绪状态。
* __就绪状态__：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
* __运行状态__：进行正在处理器上运行(单核CPU下任意时刻只有一个进程处于运行状态)。
* __阻塞状态__：进程正在等待某一事件而暂停运行如等待某资源为可用或等待IO操作完成。即使处理器空闲，该进程也不能运行。
* __结束状态__：进程从系统中消失。可能是进程正常结束或其他原因中断退出运行。
</span>

## 进程间的通信常见的有哪几种方式
<span id="jump3">

1. __管道__：具有亲缘关系的父子进程间或者兄弟进程之间的通信。
2. __有名管道__：有名管道遵循先进先出。以磁盘文件的方式存在，可以实现本机任意两个进程通信。
3. __信号__：用于通知接收进程某个事件已经发生。
4. __消息队列__：先进先出的规则。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5. __信号量__；信号量是一个计数器，用于多进程对共享数据的访问，意图在于进程间同步。
6. __共享内存__；使多个进程可以访问同一块内存空间，不同进程可以看到对方进程中对共享内存数据的更新。这种方式依靠某种同步操作，如互斥锁和信号量。这是最有用的进程间通信方式。
7. __套接字__；用于客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看做不同主机之间的进程进行双向通信的端点。
</span>

## 线程间的同步方式
<span id="jump4">

1. __互斥量__：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同步访问。Java中的synchronized关键词和各种Lock都是这种机制。
2. __信号量__：允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. __事件__：通过通知操作的方式来保持多线程同步，还可以实现多线程优先级的比较操作。
</span>

## 系统中进程的调度算法
<span id="jump5">

* __先到先服务__：从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它执行到完成或者发生某事件而被阻塞放弃占用CPU时再重新调度。
* __短作业优先__：就就绪队列中选择一个估计运行时间最短的进程为之分配资源，使它执行到完成或者发生某事件而被阻塞放弃占用CPU时再重新调度。
* __时间片轮转__：每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
* __多级反馈队列调度__：既能使高优先级的作业得到响应又能使短作业迅速完成，被公认为的一种较好的进程调度算法。UNIX操作系统采取这种调度算法。
* __优先级调度__：为每个进程分配优先级，优先执行具有最高优先级的进程，以此类推。
</span>

## 什么是死锁，产生死锁的四个必要条件是什么
<span id="jump6">

死锁就是多个进程竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。如果所申请的资源被其他等待进程占有，那么该等待进程可能再也无法改变状态，这种情况称为 __死锁__。

* __互斥__：每个资源要么已经分配给了一个进程，要么就是可用的。
* __占有并等待__：已经得到了某个资源的进程可以再请求新的资源。
* __不可抢占__：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
* __环路等待__：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。
</span>

## 内存管理有哪几种方式
<span id="jump7">
分为连续分配管理方式和非连续分配管理方式。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，如块式管理。非连续分配管理允许一个程序所使用的内存分布在离散或者说不相邻的内存中，如页式管理和段式管理。

* __块式管理__：将内存分为几个固定大小的块，每个块中只包含一个进程，如果程序运行需要内存的话，操作系统就分配给它一块。每个块中未被利用的空间，称之为碎片。
* __页式管理__：将主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
* __段式管理__：页式管理提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息。段式管理通过段表对应逻辑地址和物理地址。
* __段页式管理__：段页式管理结合了段式管理和页式管理的优点。段也是管理就是先把主存先分成若干段，每个段又分为若干页，段与段之间以及段的内部都是离散的。
简单来说，页是物理单位，段是逻辑单位。分页可以提高内存利用率，分段可以更好满足用户需求。
</span>

## 快表和多级页表

<span id="jump8">

__快表__：为了解决虚拟地址到物理地址的转换速度，操作系统在页表方案基础之上引入了快表来加速虚拟地址到物理地址的转换。把快表理解为一种特殊的高速缓冲存储器，其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。采用页表做地址转换，读写内存数据时CPU要两次访问主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：
1. 根据虚拟地址中的页号查快表;
2. 如果该页在快表中，直接从快表中读取相应的物理地址;
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中;
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰快表中的一个页。

__多级页表__：引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，也别是一些根本不需要的页表不需要保存在内存中。

为了提高内存的空间性能，提出了多级页表的概念；但是这是以浪费时间性能为基础的，为了补充损失的时间性能，提出了快表的概念。快表和多级页表都用到了程序的局部性原理。
</span>

## 分页机制和分段机制的共同点和区别
<span id="jump9">

1. __共同点__：
* 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
* 页和段是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. __区别__：
* 页的大小是固定的，由操作系统决定；段的大小不固定，取决于我们当前运行的程序。
* 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，能够更好满足用户的需要。
</span>

## CPU寻址方式及虚拟地址空间
<span id="jump10">

__虚拟寻址__：通过内存管理单元，CPU将虚拟地址转换成物理地址。
__虚拟地址空间__：如果直接把物理地址暴露出来会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。
</span>

## 虚拟内存和局部性原理
<span id="jump11">

__虚拟内存__：目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。
为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个快，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存。

__局部性原理__：
1. __时间局部性__：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。
2. __空间局部性__：一旦程序访问了某个存储单元，不久以后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据以一般是以向量、数据、表等形式簇聚存储的。

时间局部性通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了“内存——外存”的两级存储器的结构，利用局部性原理实现高速缓存。
</span>

## 虚拟内存技术的实现
<span id="jump12">

__虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。__
1. __请求分页存储管理__：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. __请求分段存储管理__：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段存储管理方式同请求分页存储管理方式一样。
3. __请求段页式存储管理__
</span>

## 页面置换算法
<span id="jump13">
地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。

> 缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。
当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，把页面置换算法当做淘汰页面的规则。
* __OPT页面置换算法__：最佳页面置换算法所选择的被淘汰页面将是以后永不使用的，或者在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。但是人们无法预知进程在内存下的若干页面哪个是未来最长时间内不再被访问的，因为该算法一般作为衡量其他置换算法的方法。
* __FIFO页面置换算法__：先进先出页面置换算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
* __LRU页面置换算法__：最近最久未使用页面置换算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当须淘汰一个页面时，选择现有页面中T值最大的，即最近最久未使用的页面予以淘汰。
* __LFU页面置换算法__：最少使用页面置换算法选择在之前时期是用最少的页面作为淘汰页。
</span>







